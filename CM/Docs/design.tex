\documentclass[a4paper]{article}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{alltt,amsmath,hyperref,graphicx}
\usepackage[usenames,dvipsnames]{xcolor}

% Link colors
\hypersetup{colorlinks=true,linkcolor=black,urlcolor=blue,citecolor=OliveGreen}

% Set paragraph indentation
\parindent 0pt
\parskip 1.0ex plus 0.5ex minus 0.2ex

\title{Concurrency and Multithreading - Design}
\author{Jayke Meijer, 2526284, jmr251, \url{jayke.meijer@gmail.com} \\
Tadde√ºs Kroes, 2526902, tks590, \url{taddeuskroes@gmail.com}}

\def\bigoh{\mathcal{O}}

\begin{document}

\maketitle
\pagebreak

\tableofcontents
\pagebreak

\section{Introduction}

This document discusses the design of several concurrent data
structures. Both an advanced design and a discussion about the
expected performance will be given for each data structure.

The data structures are the following: CoarseGrainedList,
CoarseGrainedTree, FineGrainedList, FineGrainedTree,
LockFreeList and LockFreeTree.

The difficulty with these data structures is that they are
accessed by several threads concurrently, so mutual exclusion has
to be provided for the parts where the updates take place.

\section{CoarseGrainedList}

The first data structure discussed is the CoarseGrainedList.
This is a singly-linked list. When an element is added or removed,
the entire data structure is locked.

\subsection{Design}

For the CoarseGrainedList a singly-linked list is required. To create this
list a sequence of nodes is used. These nodes contain both the stored items
and a link to the next node in the list.

To lock the list when an \emph{add} or \emph{remove} operation is performed,
a single lock is required. The lock is acquired in the beginning of the
operation. Once the lock is obtained, either the position to insert the new
node or the node to remove is located, and the remove or insert operation is
performed. Once this is done, the lock is released, allowing
other threads to do their operations.

\subsection{Performance}

The performance of the CoarseGrainedList is expected to be very poor. Almost
no parallel execution is possible, due to the fact that the entire
data structure is locked during the entire add or remove operation. This means
that whenever one thread is performing such an operation, no other thread can
do such an operation, but also not even prepare this operation, by for example
locating the nodes affected.

This means that regardless of the number of elements in the data structure,
only one thread at a time can access the list. The performance is therefore
expected to be very poor when a lot of threads are trying to execute a lot
of operations on the list.

The complexity for a single thread will be $\bigoh(n)$ with $n$ being
the number of elements in the list, since
locating the affected nodes means in worst case looping through the entire
list.

Since no parallel execution of the operations is possible, the worst-case
complexity of the entire algorithm is expected to be $\bigoh(n * m)$,
with $n$ the number of elements and $m$ the number of threads.

\section{CoarseGrainedTree}

The CoarseGrainedTree is a binary search tree. As with the
CoarseGrainedList, the complete data structure is locked when
an add or remove is performed.

\subsection{Design}

The design of the CoarseGrainedTree is similar to the design of the
CoarseGrainedList. However, the nodes used now have up to two child nodes
instead of a single following node.

The locking mechanism remains the same: the entire tree is locked before
an addition or removal operation is performed. Again, the operation performed
during the lock includes the act of locating the affected nodes.

For the addition and removal of nodes we use standard BST algorithms
\cite{insert} and \cite{delete}.

\subsection{Performance}

As with the CoarseGrainedList, the performance will be poor when a lot of
threads try to perform operations simultaneously.

The locating of the affected nodes will be faster, since we are dealing
with a binary tree instead of a list. Therefore the overall performance
will be better, due to the fact that the basic algorithm is more effective.

The complexity of a single thread is in the worst-case the same as with the
linked list, when the tree is completely unbalanced, so $\bigoh(n)$.
However, the average complexity will be better than that, and better than the
average complexity of the linked list.

If the tree is completely balanced, the complexity will be
$\bigoh(\log n)$.

Once again, these complexities are to be multiplied with the number of
threads, giving $\bigoh(n * m)$ and $\bigoh(\log(n) * m)$
respectively.

\section{FineGrainedList}

The FineGrainedList is a linked list that only locks part of the data
structure when performing an addition or removal operation. This allows
multiple threads to update the list at the same time.

\subsection{Design}

Locking is done as follows. A node is locked before its value is checked.
If this node is not the required node, the next node is locked after which the
lock on the current node is released. This way it is guaranteed that a node
can not be changed between checking its value and the actual operation on the
node. This is called \emph{Hand-over-hand} locking.

\subsection{Performance}

The advantage of this data structure is expected to be better than that of the
CoarseGrainedList, since multiple threads can operate on the list at the same
time.

However, there are some remarks to be made. The result of the 
\emph{hand-over-hand} locking is that a thread can not pass another thread
while traversing the list. This causes a delay when elements are added/removed
in ascending order. Each thread will then still have to wait on the thread in
front of him. The only advantage over the CoarseGrainedList is that while
it is waiting for the other list, it is already on its way to the proper node.

The advantage of the FineGrainedList as opposed to the CoarseGrainedList will
probably grow with the size of the list. In the FineGrainedList, part of an
operation can be performed before a locked element is encountered, whereas the
CoarseGrainedList blocks the list altogether.

However, when no two threads are accessing the list at the same time, the
FineGrainedList will have some lock overhead because elements are locked
individually. Since the test application does not add pauses between
adding/removing different elements, this case will probably not occur in the
benchmark results.

\section{FineGrainedTree}

The FineGrainedTree is a tree in which only a part of the data structure
will be locked for add or remove operations, as with the FineGrainedList.

\subsection{Design}

The design of the lock mechanism in the FineGrainTree is similar to that of the
FineGrainList. The next node visited is locked before the lock on the current
node can be released. The difference is that the current node locks one of its
child nodes next instead of the singly-linked next node.

\subsection{Performance}

With the FineGrainedList the problem was that while traversing the list, one
thread has to wait for other threads that perform their tasks. With the tree
this happens less often. When the thread A operates in another subtree than
thread B, these threads do not interfere with each other.

This effect is strongest when the tree is well balanced. Like with the
CoarseGrainedTree, when the tree is completely unbalanced it basically is
a linked list. All the advantages of the tree structure are then lost.

To maximize the advantage of a tree structure as opposed to a linked list, the
number of threads should be small in comparison to the number of elements in the
data structure. Assuming that the tree will be balanced to some degree due to the
randomness of the elements added to the tree, there will be minimum interference
between threads.

The root of the tree and first few levels of nodes can be expected to be a
bottleneck, since these will be visited by each thread for every operation.

\section{LockFreeList}

The LockFreeList is a linked list that does not use a lock when updating
the datastructure. Instead it uses a single atomic operation for both
comparing and updating, compare-and-set instructions.

\subsection{Design}

The LockFreeList operations traverse through the linked list in pairs of nodes, like
the FineGrainedList does. However, whereas the FineGrainedList locks a node before
reading its value, the LockFreeList does not. To still be able to guarantee that a
node of which the value has been read was not removed by another thread, all nodes
have a mark. The mark indicates whether a node has been logically removed from the
list (but not physically). By not physically removing the node, traversal through the
list by other threads is not interrupted. The physical removal is done by the next
thread that iterates over the node, using an abstraction of the pair-wise iteration
called a \emph{Window}. A Window iterates over the list starting from its head, and
returns two nodes that are logically in the list. Any nodes that are marked for removal
which are encountered during this iteration, are physically removed from the list. This
removal is achieved using an atomic \texttt{compareAndSet} instruction, so that no two
threads can be removing the same node at the same time. When a thread attempts to
remove a node that is already being removed by another thread, it starts iterating back
at the head of the list (because its reference to the next node has become invalid).

Apart from usage for traversal, the \texttt{compareAndSet} instruction is also used
to update references from nodes to their successors. The instruction insures that the
reference is not changed by another thread in between reading its value and updating
it.

\subsection{Performance}

In relation to the FineGrainedList, the LockFreeList should perform much better.
While the FineGrainedList can cause a congestion at a locked element in the list,
the LockFreeList allows threads to keep traversing through the list past nodes on
which operations are being performed. This advantage is especially useful for lists
with a large number of elements, in which case traversal covers a large part of the
time needed for an operation.

The LockFreeList should also scale well regarding the number of threads. Since there
are no locks, no thread will ever be halted (wait-freeness). However, with the number
of threads increasing, the change of two threads trying to remove the same marked node
at the same time increases as well. When this happens, one of the threads will have to
start traversing the list again from the head node. In terms of performance, this is an
expensive operation, especially when the list contains a large number of elements. A
reasonable expectation is that the ratio \emph{number of threads / list size} should
not be too high in order to maintain maximum performance.

\section{LockFreeTree}

The LockFreeTree uses compare-and-set instructions instead of locks.

\subsection{Design}

Design of LFT.

\subsection{Performance}

Performance Evaluation of LFT.

\begin{thebibliography}{9}

\bibitem{insert}
    Binary Search Tree: Insertion
    \url{http://www.algolist.net/Data_structures/Binary_search_tree/Insertion}
    
\bibitem{delete}
    Bianry Search Tree: Removal
    \url{http://www.algolist.net/Data_structures/Binary_search_tree/Removal}
  
\end{thebibliography}

\end{document}